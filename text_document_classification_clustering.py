# -*- coding: utf-8 -*-
"""text-document-classification-clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xgQWlawPA3l3DIMGDh-k2G39IN8UwXqf
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive/')
# %cd /gdrive

ls

cd/gdrive/MyDrive/Document_Classification/

ls

import numpy as np
import pandas as pd
import os

"""## Import Libraries"""

!pip install unidecode

!pip install contractions

! pip install pytesseract

!pip install catboost

# !unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/

import matplotlib.pyplot as plt
import seaborn as sns

#----------SKLEARN--------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import confusion_matrix,classification_report,accuracy_score
from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV


from sklearn.cluster import KMeans , AgglomerativeClustering, DBSCAN
from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer,ClusteringScoreVisualizer
from sklearn.metrics import silhouette_score


#-------NLTK--------------
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from string import punctuation
from unidecode import unidecode
from contractions import fix
from nltk.util import ngrams

from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
from nltk.stem import LancasterStemmer, WordNetLemmatizer
from wordcloud import WordCloud

#-------TENSORFLOW---------
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Input, SimpleRNN, LSTM , GRU, Bidirectional, Embedding
from keras.layers import Dropout

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

from keras.utils import to_categorical

import warnings
warnings.filterwarnings('ignore')

from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns

import pytesseract
import re

from sklearn.linear_model import SGDClassifier, LogisticRegression
from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB
from sklearn.svm import SVC

from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier

"""## Load Data"""

df = pd.read_csv("data.csv")
df

df.info()

df.columns

df['Text']

df['Text'][0]

df['Label'].value_counts().plot(kind="pie",autopct="%.1f%%")
plt.title("Document Types")
plt.legend()
plt.show()

sns.countplot(x=df['Label'])
plt.title("Document Types")
plt.show()

"""## Data Preprocessing"""

import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

import re
stopwords_list = stopwords.words("english")

def preprocess_data(text):
    text = text.lower()
    text = text.replace("\n"," ").replace("\t"," ")
    text = re.sub("\s+"," ",text)
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)

    # tokens
    tokens = word_tokenize(text)

    data = [i for i in tokens if i not in punctuation]
    data = [i for i in data if i not in stopwords_list]

    # Lemmatization
    lemmatizer = WordNetLemmatizer()
    final_text = []
    for i in data:
        word = lemmatizer.lemmatize(i)
        final_text.append(word)

    return " ".join(final_text)

clean_data = df['Text'].apply(preprocess_data)
clean_data

"""## TFIDF"""

tfidf = TfidfVectorizer(ngram_range=(1,5),max_df=0.95, max_features=15000)
tfidf_train = tfidf.fit_transform(clean_data)

tfidf_train.A.shape

tfidf_train.A

"""## Kmeans Model"""

inertia_list = []
for k in range(1,12):
    model = KMeans(n_clusters=k)
    model.fit(tfidf_train)
    inertia_list.append(model.inertia_)

inertia_list

plt.plot(range(1,12) , inertia_list, color='green', marker='o', linestyle='dashed',linewidth=2, markersize=12)
plt.title("Elbow Method",fontsize=12)
plt.xlabel("Number of Clusters",fontsize=12)
plt.ylabel("Inertia of Model")
plt.show()

from yellowbrick.cluster import KElbowVisualizer
model = KMeans(random_state=1)
visualizer = KElbowVisualizer(model, k=(2,12))  # metric='distortion'
visualizer.fit(tfidf_train.A)
visualizer.show()
plt.show()

model = KMeans(random_state=1)
visualizer = KElbowVisualizer(model, k=(2,15),metric="silhouette")
visualizer.fit(tfidf_train.A)
visualizer.show()
plt.show()

from yellowbrick.cluster import SilhouetteVisualizer

model = KMeans(n_clusters=5)
visualizer = SilhouetteVisualizer(model, colors='yellowbrick')
visualizer.fit(tfidf_train.A)
visualizer.show()
plt.show()

